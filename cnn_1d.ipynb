{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyanka-code-sys/Thesis_Priyanka/blob/main/cnn_1d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "S6e-xF6JfFX1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGE9ftkifSP4",
        "outputId": "2e720a54-7da7-420e-950a-ba6d6f4b5eee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k5Se9nU_fFX2"
      },
      "outputs": [],
      "source": [
        "#set the memory growth in the GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu,True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zemhw5mhfFX3",
        "outputId": "762ff3d3-bb98-49ef-8e83-e2e620a27457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:0,/job:localhost/replica:0/task:0/device:GPU:1\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
          ]
        }
      ],
      "source": [
        "#define strategy to use multiple gpus\n",
        "strategy = tf.distribute.MirroredStrategy([\"GPU:0\", \"GPU:1\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5VooqZZ6fFX4"
      },
      "outputs": [],
      "source": [
        "#load the dataset\n",
        "df = pd.read_pickle('/content/drive/MyDrive/dataset.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "rkL9kZOPfFX4",
        "outputId": "b8334a7d-c8bb-4068-a5f7-fed7dacbff6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>star_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1383873</th>\n",
              "      <td>don t trust the publicity if john fowler is ca...</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1141448</th>\n",
              "      <td>mesmerising how can a record so submerged in m...</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232149</th>\n",
              "      <td>oui  que vous dire sur une marchandise que j a...</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101990</th>\n",
              "      <td>mais où est donc passée la finesse de gaiman  ...</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91339</th>\n",
              "      <td>moins inspiré je suis personnellement un peu d...</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>892867</th>\n",
              "      <td>disappointed i don t right reviews very often ...</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221800</th>\n",
              "      <td>trop petit j ai retourné l article car joli ma...</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47253</th>\n",
              "      <td>je l adore mais  oui j adore stanley clarke  m...</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425195</th>\n",
              "      <td>transformer dark of the moon megatron blu ray ...</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56946</th>\n",
              "      <td>un groupe toujours aussi prenant   dommage que...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    review  star_rating\n",
              "1383873  don t trust the publicity if john fowler is ca...          0.4\n",
              "1141448  mesmerising how can a record so submerged in m...          0.8\n",
              "232149   oui  que vous dire sur une marchandise que j a...          0.6\n",
              "101990   mais où est donc passée la finesse de gaiman  ...          0.2\n",
              "91339    moins inspiré je suis personnellement un peu d...          0.6\n",
              "892867   disappointed i don t right reviews very often ...          0.4\n",
              "221800   trop petit j ai retourné l article car joli ma...          0.4\n",
              "47253    je l adore mais  oui j adore stanley clarke  m...          0.6\n",
              "425195   transformer dark of the moon megatron blu ray ...          0.6\n",
              "56946    un groupe toujours aussi prenant   dommage que...          1.0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pA-tB3JZfFX5"
      },
      "outputs": [],
      "source": [
        "#split the sentences\n",
        "df['clean_text'] = df['review'].map(lambda x:str(x).split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "H7hDFaknfFX5",
        "outputId": "769f2d52-5226-4c77-ff85-6022e21f5165"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1383873</th>\n",
              "      <td>don t trust the publicity if john fowler is ca...</td>\n",
              "      <td>0.4</td>\n",
              "      <td>[don, t, trust, the, publicity, if, john, fowl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1141448</th>\n",
              "      <td>mesmerising how can a record so submerged in m...</td>\n",
              "      <td>0.8</td>\n",
              "      <td>[mesmerising, how, can, a, record, so, submerg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232149</th>\n",
              "      <td>oui  que vous dire sur une marchandise que j a...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>[oui, que, vous, dire, sur, une, marchandise, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101990</th>\n",
              "      <td>mais où est donc passée la finesse de gaiman  ...</td>\n",
              "      <td>0.2</td>\n",
              "      <td>[mais, où, est, donc, passée, la, finesse, de,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91339</th>\n",
              "      <td>moins inspiré je suis personnellement un peu d...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>[moins, inspiré, je, suis, personnellement, un...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    review  ...                                         clean_text\n",
              "1383873  don t trust the publicity if john fowler is ca...  ...  [don, t, trust, the, publicity, if, john, fowl...\n",
              "1141448  mesmerising how can a record so submerged in m...  ...  [mesmerising, how, can, a, record, so, submerg...\n",
              "232149   oui  que vous dire sur une marchandise que j a...  ...  [oui, que, vous, dire, sur, une, marchandise, ...\n",
              "101990   mais où est donc passée la finesse de gaiman  ...  ...  [mais, où, est, donc, passée, la, finesse, de,...\n",
              "91339    moins inspiré je suis personnellement un peu d...  ...  [moins, inspiré, je, suis, personnellement, un...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MAd1Pq6yfFX6"
      },
      "outputs": [],
      "source": [
        "#load the datasets\n",
        "f = open(\"/content/drive/MyDrive/features.pkl\",'rb')\n",
        "X = pickle.load(f)\n",
        "f = open(\"/content/drive/MyDrive/labels.pkl\",'rb')\n",
        "Y = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kjIXZD1ufFX7"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GXlNg7vyfFX7"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=512, split=' ')\n",
        "tokenizer.fit_on_texts(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-V-8kc9VfFX8"
      },
      "outputs": [],
      "source": [
        "X = tokenizer.texts_to_sequences(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GZBzmswpfFX8"
      },
      "outputs": [],
      "source": [
        "X = pad_sequences(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ8qwzVLfFX8",
        "outputId": "3e6f100e-5f2b-433b-81c3-ed494d499dd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0 ...  35  20  76]\n",
            " [  0   0   0 ...  10   5 431]]\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]]\n"
          ]
        }
      ],
      "source": [
        "#check the features and vectors\n",
        "print(X[:2])\n",
        "print(Y[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6q71Y6aZfFX9"
      },
      "outputs": [],
      "source": [
        "#train test split\n",
        "X_train = X[:80000]\n",
        "Y_train = Y[:80000]\n",
        "\n",
        "X_test = X[80000:]\n",
        "Y_test = Y[80000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "N9fO1k9nfFX9"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Concatenate, Dense, Embedding, LSTM,SpatialDropout1D,Conv1D,MaxPooling1D,Flatten\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22eHerZlfFX9",
        "outputId": "2a35f9d2-ed2a-449a-b9a6-0c475c84b706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        }
      ],
      "source": [
        "#define convolution based model\n",
        "with strategy.scope():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(50000, 128, input_length= X.shape[1]))\n",
        "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(5,activation='softmax'))\n",
        "    \n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqW3C75OfFX9",
        "outputId": "a29533b2-8a5d-4f11-de83-f2dca4a0d1f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 3725, 128)         6400000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 3723, 32)          12320     \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 3721, 64)          6208      \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 3719, 64)          12352     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 238016)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                15233088  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,666,213\n",
            "Trainable params: 21,666,213\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEK2WO3NfFX-",
        "outputId": "324ebf61-80c6-4ba4-bed5-ea8481191866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2975: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use `experimental_local_results` instead.\n",
            "[[0.1994651  0.2001604  0.19984181 0.19911332 0.20141938]\n",
            " [0.200142   0.20020854 0.19910778 0.19895764 0.20158398]\n",
            " [0.19932352 0.19985303 0.20015912 0.19890875 0.20175555]]\n"
          ]
        }
      ],
      "source": [
        "pred = model.predict(X_train[:3])\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCLTALBnfFX-",
        "outputId": "e1c0ae1d-4d6b-4b63-e27f-cf0c23b6164e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "3552/8000 [============>.................] - ETA: 35:47 - loss: 1.3927 - accuracy: 0.3567"
          ]
        }
      ],
      "source": [
        "#fit the model on the dataset\n",
        "history = model.fit(X_train,Y_train,epochs=3,batch_size=8,validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRS-qef1fFX-"
      },
      "outputs": [],
      "source": [
        "#plot the history\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_loss():\n",
        "  plt.plot([1.3250,1.1709,1.1135], label='training loss')\n",
        "  plt.plot([1.2032,1.1783,1.1785], label='val loss')\n",
        "  plt.ylim([1.0, 1.5])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "plot_loss()#plot the history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCC7h32XfFX_"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy():\n",
        "  plt.plot([0.3911,0.4916,0.5193], label='training accuracy')\n",
        "  plt.plot([0.4701,0.4918,0.4848], label='val accuracy')\n",
        "  plt.ylim([0.25, 0.75])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "plot_accuracy()#plot the history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mebO3f1fFX_"
      },
      "outputs": [],
      "source": [
        "#save the model\n",
        "model.save('./cnn_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVsCVtkBfFX_"
      },
      "outputs": [],
      "source": [
        "#evaluate the model\n",
        "model.evaluate(X_test,Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0kLyDvsfFX_"
      },
      "outputs": [],
      "source": [
        "Y_preds = model.predict(X_test)\n",
        "print(Y_preds.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRpc7eVmfFYA"
      },
      "outputs": [],
      "source": [
        "Y_preds_single = np.argmax(Y_preds,axis=1)\n",
        "Y_real = np.argmax(Y_test,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVcx8wenfFYA"
      },
      "outputs": [],
      "source": [
        "#calculate the precision,recall,f1 score,confusion matrix for the model\n",
        "from sklearn.metrics import f1_score,recall_score,precision_score,ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoEOsReyfFYA"
      },
      "outputs": [],
      "source": [
        "#plot the f1 score the model across different classes\n",
        "f1 = f1_score(Y_real,Y_preds_single,average=None)\n",
        "recall = recall_score(Y_real,Y_preds_single,average=None)\n",
        "precision = precision_score(Y_real,Y_preds_single,average=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Cu3d20zfFYA"
      },
      "outputs": [],
      "source": [
        "print(\"Weighted F1 Score : \",f1_score(Y_real,Y_preds_single,average=\"weighted\"))\n",
        "print(\"Weighted Recall Score : \",recall_score(Y_real,Y_preds_single,average=\"weighted\"))\n",
        "print(\"Weighted Precision Score : \",precision_score(Y_real,Y_preds_single,average=\"weighted\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMg-j8lefFYA"
      },
      "outputs": [],
      "source": [
        "#plot the f1 score\n",
        "x = [1,2,3,4,5]\n",
        "plt.bar(x,f1,label='f1 score')\n",
        "plt.title('f1 score (all classes)')\n",
        "plt.xlabel('ratings')\n",
        "plt.ylabel('f1 score')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3znUBB4qfFYA"
      },
      "outputs": [],
      "source": [
        "#plot the recall\n",
        "x = [1,2,3,4,5]\n",
        "plt.bar(x,recall,label='recall')\n",
        "plt.title('recall (all classes)')\n",
        "plt.xlabel('ratings')\n",
        "plt.ylabel('recall')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWOoVJmqfFYA"
      },
      "outputs": [],
      "source": [
        "#precision\n",
        "x = [1,2,3,4,5]\n",
        "plt.bar(x,precision,label='precision')\n",
        "plt.title('precision (all classes)')\n",
        "plt.xlabel('ratings')\n",
        "plt.ylabel('precision')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eh5uxlsUfFYB"
      },
      "outputs": [],
      "source": [
        "#output the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(Y_real,Y_preds_single)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjDP1MM-fFYB"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(cm,annot=True,fmt='g')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQyMh4CHfFYB"
      },
      "outputs": [],
      "source": [
        "#function to test our own statements\n",
        "import re\n",
        "\n",
        "values = X_test[:3]\n",
        "print(values)\n",
        "preds = model.predict(values)\n",
        "print(\"the number of stars in the process = \",np.argmax(preds,axis=1)+1)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "6977af11dbf952fcf0436ed16e156c569ad0f9bbf70e2a2efda401ef7d9a6b7e"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "cnn_1d.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}